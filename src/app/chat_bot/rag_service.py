# chatbot_service.py - ë™ì  Few-shot ì ìš©ëœ ì±—ë´‡ ì„œë¹„ìŠ¤

import hashlib
import json
import os
from datetime import datetime
from typing import Any, Dict, List

# Django imports
from django.conf import settings
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI
# LangChain imports
from langchain.embeddings import OpenAIEmbeddings
from langchain.llms import OpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.retrievers import MultiQueryRetriever
from langchain.schema import Document
from langchain.vectorstores import Chroma

from app.knowledge_document.models import BlogPost, ChatLog, ChromaVector, CompanyContent, Project


class CompanyChatbotService:
    """íšŒì‚¬ ì±—ë´‡ ì„œë¹„ìŠ¤ - ë™ì  Few-shot Learning ì ìš©"""

    def __init__(self):
        # OpenAI ì„¤ì •
        self.embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        # self.llm = ChatOpenAI(openai_api_key=settings.OPENAI_API_KEY, model="gpt-3.5-turbo", temperature=0.1)
        self.llm = ChatOpenAI(openai_api_key=settings.OPENAI_API_KEY, model="gpt-4o", temperature=0.1)

        # Chroma ë²¡í„°ìŠ¤í† ì–´ ì„¤ì •
        self.vector_store = Chroma(
            collection_name="company_knowledge", embedding_function=self.embeddings, persist_directory="./chroma_db"
        )

        # Few-shot ì˜ˆì‹œë“¤ ì„¤ì •
        self.setup_few_shot_examples()

    def setup_few_shot_examples(self):
        """ì§ˆë¬¸ ìœ í˜•ë³„ Few-shot ì˜ˆì‹œ ì„¤ì •"""

        # íšŒì‚¬ ì†Œê°œ ê´€ë ¨ ì˜ˆì‹œ
        self.company_examples = [
            {
                "question": "ì´ íšŒì‚¬ëŠ” ë­í•˜ëŠ” íšŒì‚¬ì¸ê°€ìš”?",
                "answer": """ì•ˆë…•í•˜ì„¸ìš”! ì €í¬ ë˜‘ë˜‘í•œê°œë°œìëŠ” í˜ì‹ ì ì¸ IT ì†”ë£¨ì…˜ì„ ì œê³µí•˜ëŠ” ê°œë°œ ì „ë¬¸ íšŒì‚¬ì…ë‹ˆë‹¤.

ğŸ¢ **íšŒì‚¬ ê°œìš”**
- ì„¤ë¦½: 2020ë…„ (4ë…„ì°¨ ì„±ì¥ ê¸°ì—…)
- ì „ë¬¸ë¶„ì•¼: ì›¹/ì•± ê°œë°œ, AI ì†”ë£¨ì…˜, í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤
- íŒ€ êµ¬ì„±: ì‹œë‹ˆì–´ ê°œë°œì ì¤‘ì‹¬ì˜ ì „ë¬¸ ì¸ë ¥

ğŸ’¡ **í•µì‹¬ ê°•ì **
- ìµœì‹  ê¸°ìˆ  ìŠ¤íƒ ê¸°ë°˜ ê°œë°œ
- ê³ ê° ë§ì¶¤í˜• ì†”ë£¨ì…˜ ì œê³µ
- ë¹ ë¥¸ ê°œë°œ ì£¼ê¸°ì™€ ì•ˆì •ì ì¸ ìš´ì˜

ğŸ¯ **ì£¼ìš” ê³ ê°ì¸µ**
- ìŠ¤íƒ€íŠ¸ì—…ë¶€í„° ì¤‘ê²¬ê¸°ì—…ê¹Œì§€
- ë””ì§€í„¸ ì „í™˜ì´ í•„ìš”í•œ ê¸°ì—…ë“¤""",
            },
            {
                "question": "íŒ€ êµ¬ì„±ì€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
                "answer": """ì €í¬ íŒ€ì€ ê° ë¶„ì•¼ë³„ ì „ë¬¸ê°€ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

ğŸ‘¥ **íŒ€ êµ¬ì„±**
- **ê°œë°œíŒ€ (17ëª…)**: í’€ìŠ¤íƒ, í”„ë¡ íŠ¸ì—”ë“œ, ë°±ì—”ë“œ ì „ë¬¸ê°€
- **ë””ìì¸íŒ€ (8ëª…)**: UI/UX, ê·¸ë˜í”½ ë””ìì¸
- **ê¸°íšíŒ€ (4ëª…)**: í”„ë¡œì íŠ¸ ë§¤ë‹ˆì €

ğŸŒŸ **íŒ€ì˜ íŠ¹ì§•**
- í‰ê·  ê²½ë ¥ 5ë…„+ ì‹œë‹ˆì–´ ê°œë°œì ì¤‘ì‹¬
- ì• ìì¼ ë°©ë²•ë¡  ê¸°ë°˜ í˜‘ì—…
- ì§€ì†ì ì¸ ê¸°ìˆ  í•™ìŠµê³¼ ê³µìœ  ë¬¸í™”""",
            },
        ]

        # í”„ë¡œì íŠ¸ ê´€ë ¨ ì˜ˆì‹œ
        self.project_examples = [
            {
                "question": "ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í–ˆë‚˜ìš”?",
                "answer": """ë‹¤ì–‘í•œ ë¶„ì•¼ì˜ í˜ì‹ ì ì¸ í”„ë¡œì íŠ¸ë“¤ì„ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.

ğŸŒŸ **ëŒ€í‘œ í”„ë¡œì íŠ¸**

**ğŸ’° í•€í…Œí¬ í”Œë«í¼**
- ê°œë°œê¸°ê°„: 8ê°œì›”, íŒ€ ê·œëª¨: 6ëª…
- ê¸°ìˆ ìŠ¤íƒ: React, Django, PostgreSQL, Redis
- ì£¼ìš”ê¸°ëŠ¥: ê°„í¸ê²°ì œ, ìì‚°ê´€ë¦¬, íˆ¬ììƒí’ˆ ì—°ë™

**ğŸ›’ ì´ì»¤ë¨¸ìŠ¤ ì†”ë£¨ì…˜**
- ê°œë°œê¸°ê°„: 6ê°œì›”, íŒ€ ê·œëª¨: 5ëª…  
- ê¸°ìˆ ìŠ¤íƒ: Vue.js, FastAPI, MongoDB
- ì£¼ìš”ê¸°ëŠ¥: ìƒí’ˆê´€ë¦¬, ì£¼ë¬¸ê²°ì œ, ì¬ê³ ê´€ë¦¬, ë¶„ì„ëŒ€ì‹œë³´ë“œ

**ğŸ¤– AI ì±—ë´‡ ì‹œìŠ¤í…œ**
- ê°œë°œê¸°ê°„: 4ê°œì›”, íŒ€ ê·œëª¨: 4ëª…
- ê¸°ìˆ ìŠ¤íƒ: Python, LangChain, OpenAI API, Chroma
- ì£¼ìš”ê¸°ëŠ¥: ìì—°ì–´ ì²˜ë¦¬, ë¬¸ì„œ ê²€ìƒ‰, í•™ìŠµ ê¸°ëŠ¥""",
            },
            {
                "question": "í¬íŠ¸í´ë¦¬ì˜¤ í•˜ì´ë¼ì´íŠ¸ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”",
                "answer": """ì €í¬ì˜ ëŒ€í‘œì ì¸ ì„±ê³µ ì‚¬ë¡€ë“¤ì„ ì†Œê°œí•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.

ğŸ† **í¬íŠ¸í´ë¦¬ì˜¤ í•˜ì´ë¼ì´íŠ¸**

**1. ìŠ¤ë§ˆíŠ¸ ë¬¼ë¥˜ ê´€ë¦¬ ì‹œìŠ¤í…œ**
- ëŒ€ê¸°ì—… ê³„ì—´ì‚¬ í”„ë¡œì íŠ¸
- ê°œë°œê¸°ê°„: 10ê°œì›”, íˆ¬ì…ì¸ë ¥: 8ëª…
- ì„±ê³¼: ì—…ë¬´ íš¨ìœ¨ì„± 40% í–¥ìƒ, ë¹„ìš© ì ˆê° 30%

**2. í—¬ìŠ¤ì¼€ì–´ ëª¨ë°”ì¼ ì•±**
- ì˜ë£Œì§„-í™˜ì ì—°ê²° í”Œë«í¼
- ì›” í™œì„± ì‚¬ìš©ì 50,000ëª… ëŒíŒŒ
- ì•±ìŠ¤í† ì–´ í‰ì  4.8ì  ìœ ì§€

**3. êµìœ¡ í”Œë«í¼ êµ¬ì¶•**
- ì˜¨ë¼ì¸ í•™ìŠµ ê´€ë¦¬ ì‹œìŠ¤í…œ
- ë™ì‹œ ì ‘ì†ì 10,000ëª… ì²˜ë¦¬ ê°€ëŠ¥
- ì‹¤ì‹œê°„ í™”ìƒ ìˆ˜ì—… ê¸°ëŠ¥ êµ¬í˜„""",
            },
        ]

        # ê¸°ìˆ  ìŠ¤íƒ ê´€ë ¨ ì˜ˆì‹œ
        self.tech_examples = [
            {
                "question": "React ê°œë°œ ê°€ëŠ¥í•œê°€ìš”?",
                "answer": """ë„¤! ReactëŠ” ì €í¬ì˜ í•µì‹¬ í”„ë¡ íŠ¸ì—”ë“œ ê¸°ìˆ ì…ë‹ˆë‹¤.

âš›ï¸ **React ì „ë¬¸ ì—­ëŸ‰**
- **ê²½í—˜**: 3ë…„+ ì‹¤ë¬´ ê²½í—˜, 10ê°œ+ í”„ë¡œë•ì…˜ í”„ë¡œì íŠ¸
- **ê´€ë ¨ ê¸°ìˆ **: Next.js, TypeScript, Redux Toolkit, React Query
- **í”„ë¡œì íŠ¸ ê·œëª¨**: ì†Œê·œëª¨ ëœë”©í˜ì´ì§€ë¶€í„° ëŒ€ê·œëª¨ SPAê¹Œì§€

ğŸ› ï¸ **ê°œë°œ ì „ë¬¸ì„±**
- ì„±ëŠ¥ ìµœì í™” (Code Splitting, Lazy Loading)
- ë°˜ì‘í˜• ë””ìì¸ ë° í¬ë¡œìŠ¤ë¸Œë¼ìš°ì§•
- í…ŒìŠ¤íŠ¸ ì½”ë“œ ì‘ì„± (Jest, React Testing Library)
- ìƒíƒœ ê´€ë¦¬ íŒ¨í„´ ì„¤ê³„

ğŸ“ˆ **ìµœê·¼ React í”„ë¡œì íŠ¸**
- í•€í…Œí¬ ëŒ€ì‹œë³´ë“œ (TypeScript + Next.js)
- ì‹¤ì‹œê°„ ì±„íŒ… ì•± (Socket.io ì—°ë™)
- ê´€ë¦¬ì í˜ì´ì§€ (Material-UI í™œìš©)""",
            },
            {
                "question": "ë°±ì—”ë“œ ê°œë°œì€ ì–´ë–¤ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ë‚˜ìš”?",
                "answer": """ë‹¤ì–‘í•œ ë°±ì—”ë“œ ê¸°ìˆ  ìŠ¤íƒìœ¼ë¡œ ì•ˆì •ì ì¸ ì„œë²„ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤.

ğŸ”§ **ì£¼ìš” ë°±ì—”ë“œ ê¸°ìˆ **

**Python ìƒíƒœê³„**
- Django REST Framework (API ì„œë²„)
- FastAPI (ê³ ì„±ëŠ¥ ë¹„ë™ê¸° API)
- Celery (ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì²˜ë¦¬)

**Node.js ìƒíƒœê³„**  
- Express.js (ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘)
- NestJS (ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì• í”Œë¦¬ì¼€ì´ì…˜)

**ë°ì´í„°ë² ì´ìŠ¤**
- PostgreSQL (ê´€ê³„í˜• DB)
- MongoDB (NoSQL)
- Redis (ìºì‹±, ì„¸ì…˜ ê´€ë¦¬)

â˜ï¸ **í´ë¼ìš°ë“œ & ì¸í”„ë¼**
- AWS (EC2, RDS, S3, Lambda)
- Docker ì»¨í…Œì´ë„ˆí™”
- CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶•""",
            },
        ]

        # ì¼ë°˜ì ì¸/ê¸°íƒ€ ì˜ˆì‹œ
        self.general_examples = [
            {
                "question": "ê²¬ì  ë¬¸ì˜ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",
                "answer": """í”„ë¡œì íŠ¸ ê²¬ì  ë¬¸ì˜ëŠ” ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ğŸ“ **ê²¬ì  ë¬¸ì˜ ë°©ë²•**
- **ì´ë©”ì¼**: contact@toktokhan.dev
- **ì „í™”**: 02-1234-5678 (í‰ì¼ 9ì‹œ-18ì‹œ)
- **ì¹´ì¹´ì˜¤í†¡**: @ë˜‘ë˜‘í•œê°œë°œì
- **í™ˆí˜ì´ì§€**: ì˜¨ë¼ì¸ ê²¬ì  ë¬¸ì˜ í¼ ì‘ì„±

ğŸ“‹ **ê²¬ì ì— í•„ìš”í•œ ì •ë³´**
- í”„ë¡œì íŠ¸ ê°œìš” ë° ëª©ì 
- ì£¼ìš” ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­
- ì˜ˆìƒ ì¼ì • ë° ì˜ˆì‚° ë²”ìœ„
- ì°¸ê³  ì‚¬ì´íŠ¸ë‚˜ ì•±ì´ ìˆë‹¤ë©´

â° **ê²¬ì  ì œê³µ ì¼ì •**
- ê°„ë‹¨í•œ í”„ë¡œì íŠ¸: 1-2ì¼ ë‚´
- ë³µì¡í•œ í”„ë¡œì íŠ¸: 3-5ì¼ ë‚´ ìƒì„¸ ì œì•ˆì„œ ì œê³µ

ğŸ’¡ **ë¬´ë£Œ ì»¨ì„¤íŒ…**
- ì´ˆê¸° ê¸°íš ë‹¨ê³„ ë¬´ë£Œ ìƒë‹´ ê°€ëŠ¥
- ê¸°ìˆ  ìŠ¤íƒ ì¶”ì²œ ë° ì•„í‚¤í…ì²˜ ì„¤ê³„ ì¡°ì–¸""",
            }
        ]

    def _analyze_question_type(self, question: str) -> str:
        """ì ìˆ˜ ê¸°ë°˜ ì§ˆë¬¸ ìœ í˜• ë¶„ì„ - ë³µí•© ì§ˆë¬¸ ì²˜ë¦¬ ê°œì„ """
        question_lower = question.lower()

        # ì ìˆ˜ ì´ˆê¸°í™”
        scores = {"company": 0.0, "project": 0.0, "tech": 0.0, "general": 0.0}

        # í‚¤ì›Œë“œë³„ ê°€ì¤‘ì¹˜ ë§¤í•‘ (ê¸°ì¡´ í‚¤ì›Œë“œ + ê°€ì¤‘ì¹˜)
        keyword_weights = {
            "company": {
                "íšŒì‚¬": 1.0,
                "ê¸°ì—…": 1.0,
                "íŒ€": 0.8,
                "ì¡°ì§": 0.8,
                "ì†Œê°œ": 0.6,
                "ì„¤ë¦½": 0.8,
                "ì§ì›": 0.7,
                "êµ¬ì„±ì›": 0.7,
                "ë¬¸í™”": 0.6,
            },
            "project": {
                "í”„ë¡œì íŠ¸": 2.0,
                "í¬íŠ¸í´ë¦¬ì˜¤": 1.8,
                "ê°œë°œ": 1.2,
                "ì§„í–‰": 1.0,
                "ê²½í—˜": 0.8,
                "ì‚¬ë¡€": 1.2,
                "êµ¬ì¶•": 1.3,
                "ì œì‘": 1.2,
                "ì™„ë£Œ": 1.0,
                "ì§„í–‰í–ˆë˜": 1.5,
                "ì§„í–‰í•œ": 1.5,
                "ì‘ì—…": 0.8,
                "ì—…ë¬´": 0.8,
            },
            "tech": {
                # êµ¬ì²´ì  ê¸°ìˆ ëª… (ë†’ì€ ê°€ì¤‘ì¹˜)
                "react": 2.0,
                "vue": 2.0,
                "angular": 2.0,
                "javascript": 1.8,
                "typescript": 1.8,
                "python": 2.0,
                "django": 2.0,
                "fastapi": 1.8,
                "node": 1.8,
                "express": 1.8,
                "spring": 1.8,
                "java": 1.8,
                "php": 1.8,
                "laravel": 1.8,
                "mysql": 1.5,
                "postgresql": 1.5,
                "mongodb": 1.5,
                "redis": 1.5,
                "aws": 1.8,
                "docker": 1.8,
                "kubernetes": 1.8,
                # ì¼ë°˜ ê¸°ìˆ  ìš©ì–´
                "ê¸°ìˆ ": 1.0,
                "ìŠ¤íƒ": 1.2,
                "ì–¸ì–´": 1.0,
                "í”„ë ˆì„ì›Œí¬": 1.2,
                "ë°ì´í„°ë² ì´ìŠ¤": 1.0,
                "í´ë¼ìš°ë“œ": 1.0,
                "ì¸í”„ë¼": 1.0,
            },
        }

        # ê¸°ë³¸ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚°
        for category, keywords in keyword_weights.items():
            for keyword, weight in keywords.items():
                if keyword in question_lower:
                    scores[category] += weight

        # íŠ¹ë³„ íŒ¨í„´ ë³´ë„ˆìŠ¤ ì ìˆ˜
        self._apply_pattern_bonuses(question_lower, scores)

        # ë³µí•© ì§ˆë¬¸ ì²˜ë¦¬ ë¡œì§
        return self._determine_final_type(scores, question_lower)

    def _apply_pattern_bonuses(self, question_lower: str, scores: dict):
        """ì§ˆë¬¸ íŒ¨í„´ì— ë”°ë¥¸ ë³´ë„ˆìŠ¤ ì ìˆ˜ ì ìš©"""

        # í”„ë¡œì íŠ¸ ì§ˆë¬¸ íŒ¨í„´
        project_patterns = [
            ("ë¡œ ì§„í–‰í•œ", 1.5),
            ("ë¡œ ê°œë°œí•œ", 1.5),
            ("ì„ ì‚¬ìš©í•œ", 1.2),
            ("ë¡œ ë§Œë“ ", 1.3),
            ("ê¸°ìˆ ë¡œ", 1.0),
            ("ìŠ¤íƒìœ¼ë¡œ", 1.0),
            ("í”„ë¡œì íŠ¸ ì¤‘ì—", 1.8),
            ("í¬íŠ¸í´ë¦¬ì˜¤", 1.5),
            ("ì§„í–‰í–ˆë˜", 1.3),
            ("ê°œë°œí–ˆë˜", 1.3),
            ("ì–´ë–¤ í”„ë¡œì íŠ¸", 1.5),
        ]

        for pattern, bonus in project_patterns:
            if pattern in question_lower:
                scores["project"] += bonus

        # ê¸°ìˆ  ì§ˆë¬¸ íŒ¨í„´
        tech_patterns = [
            ("ê°€ëŠ¥í•œê°€ìš”", 1.5),
            ("í•  ìˆ˜ ìˆë‚˜ìš”", 1.5),
            ("í•  ìˆ˜ ìˆì–´ìš”", 1.5),
            ("ê°œë°œ ê°€ëŠ¥", 1.5),
            ("ê¸°ìˆ  ìŠ¤íƒ", 1.3),
            ("ì‚¬ìš©í•˜ë‚˜ìš”", 1.2),
            ("ê²½í—˜ì´ ìˆë‚˜ìš”", 1.3),
            ("ê²½í—˜ì´ ìˆì–´ìš”", 1.3),
            ("ë‹¤ë£° ìˆ˜ ìˆë‚˜ìš”", 1.4),
            ("ì–´ë–¤ ê¸°ìˆ ", 1.2),
            ("ì–´ë–¤ ì–¸ì–´", 1.2),
            ("ë°±ì—”ë“œ", 1.2),
            ("í”„ë¡ íŠ¸ì—”ë“œ", 1.2),
        ]

        for pattern, bonus in tech_patterns:
            if pattern in question_lower:
                scores["tech"] += bonus

        # íšŒì‚¬ ì§ˆë¬¸ íŒ¨í„´
        company_patterns = [
            ("ë­í•˜ëŠ” íšŒì‚¬", 2.0),
            ("ì–´ë–¤ íšŒì‚¬", 1.5),
            ("íšŒì‚¬ ì†Œê°œ", 1.8),
            ("íŒ€ êµ¬ì„±", 1.5),
            ("íšŒì‚¬ ë¬¸í™”", 1.5),
            ("ì¡°ì§ êµ¬ì„±", 1.3),
        ]

        for pattern, bonus in company_patterns:
            if pattern in question_lower:
                scores["company"] += bonus

    def _determine_final_type(self, scores: dict, question_lower: str) -> str:
        """ìµœì¢… ì§ˆë¬¸ ìœ í˜• ê²°ì •"""

        # ë””ë²„ê¹…ì„ ìœ„í•œ ì ìˆ˜ ì¶œë ¥ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
        # print(f"ì ìˆ˜ ë¶„ì„: {scores}")

        # ìµœê³  ì ìˆ˜ ì¹´í…Œê³ ë¦¬ë“¤ ì°¾ê¸°
        max_score = max(scores.values())

        # ëª¨ë“  ì ìˆ˜ê°€ 0ì¸ ê²½ìš°
        if max_score == 0:
            return "general"

        # ìµœê³  ì ìˆ˜ë¥¼ ê°€ì§„ ì¹´í…Œê³ ë¦¬ë“¤
        top_categories = [cat for cat, score in scores.items() if score == max_score]

        # ë™ì ì¸ ê²½ìš° ìš°ì„ ìˆœìœ„ ì ìš©
        if len(top_categories) > 1:
            return self._resolve_tie(top_categories, scores, question_lower)

        return top_categories[0]

    def _resolve_tie(self, tied_categories: list, scores: dict, question_lower: str) -> str:
        """ë™ì  ì‹œ ìš°ì„ ìˆœìœ„ ê²°ì •"""

        # ìš°ì„ ìˆœìœ„ ê·œì¹™
        priority_rules = [
            # 1ìˆœìœ„: tech + project ì¡°í•© â†’ êµ¬ì²´ì  ê¸°ìˆ  ì–¸ê¸‰ ì—¬ë¶€ë¡œ ê²°ì •
            (["tech", "project"], self._tech_project_resolver),
            # 2ìˆœìœ„: company + project ì¡°í•© â†’ project ìš°ì„  (ì‹¤ì œ ì •ë³´ ìš”ì²­)
            (["company", "project"], lambda q: "project"),
            # 3ìˆœìœ„: company + tech ì¡°í•© â†’ tech ìš°ì„  (êµ¬ì²´ì  ì—­ëŸ‰ ë¬¸ì˜)
            (["company", "tech"], lambda q: "tech"),
            # 4ìˆœìœ„: ì „ì²´ ë™ì  â†’ project ìš°ì„  (ê°€ì¥ êµ¬ì²´ì  ì •ë³´)
            (["company", "project", "tech"], lambda q: "project"),
        ]

        for rule_categories, resolver in priority_rules:
            if set(tied_categories) == set(rule_categories):
                if callable(resolver):
                    return resolver(question_lower)
                else:
                    return resolver

        # ê¸°ë³¸ê°’: ì•ŒíŒŒë²³ ìˆœì„œë¡œ ì²« ë²ˆì§¸
        return sorted(tied_categories)[0]

    def _tech_project_resolver(self, question_lower: str) -> str:
        """tech vs project ë™ì  ì‹œ ê²°ì • ë¡œì§"""

        # êµ¬ì²´ì  ê¸°ìˆ ëª…ì´ ë§ì´ ì–¸ê¸‰ëœ ê²½ìš° â†’ tech
        specific_techs = ["react", "vue", "angular", "django", "python", "node", "java"]
        tech_mentions = sum(1 for tech in specific_techs if tech in question_lower)

        # í”„ë¡œì íŠ¸ ê´€ë ¨ ë™ì‚¬ê°€ ìˆëŠ” ê²½ìš° â†’ project
        project_verbs = ["ì§„í–‰", "ê°œë°œ", "ë§Œë“ ", "êµ¬ì¶•", "ì œì‘", "ì™„ë£Œ"]
        project_verb_mentions = sum(1 for verb in project_verbs if verb in question_lower)

        if tech_mentions >= 2:  # ê¸°ìˆ ëª… 2ê°œ ì´ìƒ â†’ tech ìš°ì„ 
            return "tech"
        elif project_verb_mentions > 0:  # í”„ë¡œì íŠ¸ ë™ì‚¬ ìˆìŒ â†’ project ìš°ì„ 
            return "project"
        else:
            return "project"  # ê¸°ë³¸ê°’: project (ë” êµ¬ì²´ì  ì •ë³´)

    # êµ¬ë²„ì „
    # def _analyze_question_type(self, question: str) -> str:
    #     """ì§ˆë¬¸ ìœ í˜• ë¶„ì„"""
    #     question_lower = question.lower()
    #
    #     # íšŒì‚¬ ê´€ë ¨ í‚¤ì›Œë“œ
    #     company_keywords = ["íšŒì‚¬", "ê¸°ì—…", "íŒ€", "ì¡°ì§", "ì†Œê°œ", "ì„¤ë¦½", "ì§ì›", "êµ¬ì„±ì›", "ë¬¸í™”"]
    #
    #     # í”„ë¡œì íŠ¸ ê´€ë ¨ í‚¤ì›Œë“œ
    #     project_keywords = ["í”„ë¡œì íŠ¸", "í¬íŠ¸í´ë¦¬ì˜¤", "ê°œë°œ", "ì§„í–‰", "ê²½í—˜", "ì‚¬ë¡€", "êµ¬ì¶•", "ì œì‘", "ì™„ë£Œ"]
    #
    #     # ê¸°ìˆ  ê´€ë ¨ í‚¤ì›Œë“œ
    #     tech_keywords = [
    #         "react",
    #         "vue",
    #         "angular",
    #         "javascript",
    #         "typescript",
    #         "python",
    #         "django",
    #         "fastapi",
    #         "node",
    #         "express",
    #         "spring",
    #         "java",
    #         "php",
    #         "laravel",
    #         "mysql",
    #         "postgresql",
    #         "mongodb",
    #         "redis",
    #         "aws",
    #         "docker",
    #         "kubernetes",
    #         "ê¸°ìˆ ",
    #         "ìŠ¤íƒ",
    #         "ì–¸ì–´",
    #         "í”„ë ˆì„ì›Œí¬",
    #         "ë°ì´í„°ë² ì´ìŠ¤",
    #         "í´ë¼ìš°ë“œ",
    #         "ì¸í”„ë¼",
    #         "ê°œë°œ",
    #     ]
    #
    #     # í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ì§ˆë¬¸ ìœ í˜• íŒë‹¨
    #     if any(keyword in question_lower for keyword in company_keywords):
    #         return "company"
    #     elif any(keyword in question_lower for keyword in project_keywords):
    #         return "project"
    #     elif any(keyword in question_lower for keyword in tech_keywords):
    #         return "tech"
    #     else:
    #         return "general"

    def _get_examples_by_question_type(self, question_type: str) -> List[Dict]:
        """ì§ˆë¬¸ ìœ í˜•ë³„ ì˜ˆì‹œ ë°˜í™˜"""
        examples_map = {
            "company": self.company_examples,
            "project": self.project_examples,
            "tech": self.tech_examples,
            "general": self.general_examples,
        }
        return examples_map.get(question_type, self.general_examples)

    def _build_few_shot_prompt(self, question: str, context: str) -> str:
        """ë™ì  Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„±"""

        # ì§ˆë¬¸ ìœ í˜• ë¶„ì„
        question_type = self._analyze_question_type(question)
        examples = self._get_examples_by_question_type(question_type)

        # Few-shot ì˜ˆì‹œ êµ¬ì„±
        examples_text = ""
        for i, example in enumerate(examples[:2], 1):  # ìµœëŒ€ 2ê°œ ì˜ˆì‹œ ì‚¬ìš©
            examples_text += f"""
ì˜ˆì‹œ {i}:
ì§ˆë¬¸: "{example['question']}"
ë‹µë³€: {example['answer']}

"""

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""ë‹¹ì‹ ì€ ë˜‘ë˜‘í•œê°œë°œìì˜ ì „ë¬¸ AI ìƒë‹´ì›ì…ë‹ˆë‹¤. ì•„ë˜ ì˜ˆì‹œë“¤ì„ ì°¸ê³ í•˜ì—¬ ë¹„ìŠ·í•œ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

{examples_text}

# ë‹µë³€ ê°€ì´ë“œë¼ì¸
1. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ ìœ ì§€
2. êµ¬ì²´ì ì¸ ì •ë³´ì™€ ë°ì´í„° í¬í•¨  
3. ì´ëª¨ì§€ë¥¼ í™œìš©í•œ ê°€ë…ì„± í–¥ìƒ
4. êµ¬ì¡°í™”ëœ ë‹µë³€ í˜•ì‹ ì‚¬ìš©
5. ê´€ë ¨ ë¸”ë¡œê·¸ê°€ ìˆë‹¤ë©´ "ğŸ“ ê´€ë ¨ ë¸”ë¡œê·¸" ì„¹ì…˜ ì¶”ê°€

# ğŸ“ ë§ˆí¬ë‹¤ìš´ í¬ë§·íŒ… ê·œì¹™ (ì¤‘ìš”!)
1. **ëª©ë¡ ì‘ì„± ì‹œ**: í•˜ì´í”ˆ(-) ë˜ëŠ” ìˆ«ì(1.) ì‚¬ìš©, â€¢ ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€
2. **ê°•ì¡°**: **êµµì€ ê¸€ì”¨** ì‚¬ìš©
3. **êµ¬ì¡°**: ## ëŒ€ì œëª©, **ì†Œì œëª©** í˜•ì‹
4. **ëª©ë¡ ì˜ˆì‹œ**:
   - í•­ëª© 1: ì„¤ëª…
   - í•­ëª© 2: ì„¤ëª…
   ë˜ëŠ”
   1. ì²« ë²ˆì§¸ í•­ëª©
   2. ë‘ ë²ˆì§¸ í•­ëª©

# âš ï¸ ì¤‘ìš”í•œ ë‹µë³€ ê·œì¹™
1. **ê²€ìƒ‰ëœ ì •ë³´ì—ë§Œ ê¸°ë°˜í•˜ì—¬ ë‹µë³€** - ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ìƒì„±í•˜ì§€ ë§ˆì„¸ìš”
2. ê´€ë ¨ ì •ë³´ê°€ ì—†ìœ¼ë©´ "ì£„ì†¡í•˜ì§€ë§Œ í•´ë‹¹ ë¶„ì•¼ ê´€ë ¨ í”„ë¡œì íŠ¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ì†”ì§í•˜ê²Œ ë‹µë³€
3. ì¶”ì¸¡ì´ë‚˜ ê°€ì •ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”
4. ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ ë¬¸ì˜ ë°©ë²•ì„ ì•ˆë‚´í•´ì£¼ì„¸ìš”

# ì˜ˆì‹œ - ì •ë³´ê°€ ì—†ëŠ” ê²½ìš°:
Q: "ë¸”ë¡ì²´ì¸ ê°œë°œ ê²½í—˜ì´ ìˆë‚˜ìš”?"
A: ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì €í¬ê°€ ë³´ìœ í•œ ìë£Œì—ëŠ” ë¸”ë¡ì²´ì¸ ê´€ë ¨ í”„ë¡œì íŠ¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. 

ë” ìì„¸í•œ ì •ë³´ê°€ í•„ìš”í•˜ì‹œë‹¤ë©´ ì•„ë˜ë¡œ ë¬¸ì˜í•´ì£¼ì„¸ìš”:
ğŸ“ **ë¬¸ì˜ ë°©ë²•**
- ì´ë©”ì¼: contact@toktokhan.dev  
- ì „í™”: 02-1234-5678

# í˜„ì¬ ê²€ìƒ‰ëœ íšŒì‚¬ ì •ë³´
{context}

# ì‚¬ìš©ì ì§ˆë¬¸
{question}

ë‹µë³€:"""

        return prompt

    def _generate_final_answer(self, question: str, context_info: Dict, related_blogs: List) -> str:
        """ë™ì  Few-shotì„ ì ìš©í•œ ìµœì¢… ë‹µë³€ ìƒì„±"""

        # ë™ì  Few-shot í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_text = self._build_few_shot_prompt(question, context_info["context_text"])

        # ë¸”ë¡œê·¸ ì„¹ì…˜ ì¶”ê°€
        if related_blogs:
            blog_section = "\n\n# ë‹µë³€ì— í¬í•¨í•  ê´€ë ¨ ë¸”ë¡œê·¸\n"
            for blog in related_blogs:
                blog_section += f"- [{blog['title']}]({blog['url']})\n"
            prompt_text += blog_section

        # ChatGPT í˜¸ì¶œ
        messages = [{"role": "user", "content": prompt_text}]
        response = self.llm.invoke(messages)

        return response.content

    # ê¸°ì¡´ ë©”ì„œë“œë“¤ì€ ê·¸ëŒ€ë¡œ ìœ ì§€...
    def embed_all_content(self):
        """ëª¨ë“  ì»¨í…ì¸ ë¥¼ í¬ë¡œë§ˆì— ì„ë² ë”©"""
        print("ğŸ”„ ëª¨ë“  ì»¨í…ì¸  ì„ë² ë”© ì‹œì‘...")

        # 1. íšŒì‚¬ ì»¨í…ì¸  ì„ë² ë”©
        company_contents = CompanyContent.objects.filter(is_active=True)
        for content in company_contents:
            self._embed_company_content(content)

        # 2. í”„ë¡œì íŠ¸ ì„ë² ë”©
        projects = Project.objects.all()
        for project in projects:
            self._embed_project(project)

        # 3. ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì„ë² ë”©
        blog_posts = BlogPost.objects.filter(is_active=True)
        for blog_post in blog_posts:
            self._embed_blog_post(blog_post)

        print("âœ… ì„ë² ë”© ì™„ë£Œ!")

    def _embed_company_content(self, content: CompanyContent):
        """íšŒì‚¬ ì»¨í…ì¸  ì„ë² ë”©"""
        embed_text = f"""
        ì œëª©: {content.title}
        ìœ í˜•: {content.get_content_type_display()}
        ì¹´í…Œê³ ë¦¬: {content.category.name}
        ë‚´ìš©: {content.content}
        íƒœê·¸: {', '.join(content.tags)}
        ê²€ìƒ‰í‚¤ì›Œë“œ: {content.search_keywords}
        """

        metadata = {
            "source_type": "company_content",
            "content_id": str(content.id),
            "title": content.title,
            "content_type": content.content_type,
            "category": content.category.name,
            "priority": content.priority,
            "is_featured": content.is_featured,
            "tags": ", ".join(content.tags) if content.tags else "",
        }

        document = Document(page_content=embed_text, metadata=metadata)
        vector_id = f"company_{content.id}"
        self.vector_store.add_documents([document], ids=[vector_id])

        ChromaVector.objects.update_or_create(
            content_type="company_content",
            content_id=content.id,
            defaults={
                "vector_id": vector_id,
                "collection_name": "company_knowledge",
                "source_content_hash": self._get_content_hash(embed_text),
                "needs_update": False,
            },
        )

    def _embed_project(self, project: Project):
        """í”„ë¡œì íŠ¸ ì„ë² ë”©"""
        embed_text = f"""
        í”„ë¡œì íŠ¸ëª…: {project.name}
        í”„ë¡œì íŠ¸ ìœ í˜•: {project.get_project_type_display()}
        í´ë¼ì´ì–¸íŠ¸: {project.client_name}
        ì„¤ëª…: {project.description}
        ì£¼ìš” ê¸°ëŠ¥: {', '.join(project.key_features)}
        ì‚¬ìš© ê¸°ìˆ : {', '.join(project.technologies_used)}
        íŒ€ í¬ê¸°: {project.team_size}ëª…
        ê°œë°œ ê¸°ê°„: {project.duration_months}ê°œì›”
        ìƒíƒœ: {project.get_status_display()}
        í¬íŠ¸í´ë¦¬ì˜¤ ëŒ€í‘œ: {'ì˜ˆ' if project.is_portfolio_highlight else 'ì•„ë‹ˆì˜¤'}
        ê²€ìƒ‰íƒœê·¸: {', '.join(project.search_tags)}
        """

        metadata = {
            "source_type": "project",
            "content_id": str(project.id),
            "project_name": project.name,
            "project_type": project.project_type,
            "client_name": project.client_name,
            "technologies": ", ".join(project.technologies_used) if project.technologies_used else "",
            "is_highlight": project.is_portfolio_highlight,
            "duration_months": project.duration_months,
            "team_size": project.team_size,
        }

        document = Document(page_content=embed_text, metadata=metadata)
        vector_id = f"project_{project.id}"
        self.vector_store.add_documents([document], ids=[vector_id])

        ChromaVector.objects.update_or_create(
            content_type="project",
            content_id=project.id,
            defaults={
                "vector_id": vector_id,
                "collection_name": "company_knowledge",
                "source_content_hash": self._get_content_hash(embed_text),
                "needs_update": False,
            },
        )

    def _embed_blog_post(self, blog_post: BlogPost):
        """ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì„ë² ë”©"""
        embed_text = f"""
        ë¸”ë¡œê·¸ ì œëª©: {blog_post.title}
        ë°œì·Œ: {blog_post.excerpt}
        ë‚´ìš© ìš”ì•½: {blog_post.content_summary}
        ê´€ë ¨ ì£¼ì œ: {', '.join(blog_post.related_topics)}
        URL: {blog_post.url}
        """

        metadata = {
            "source_type": "blog_post",
            "content_id": str(blog_post.id),
            "title": blog_post.title,
            "url": blog_post.url,
            "related_topics": ", ".join(blog_post.related_topics) if blog_post.related_topics else "",
            "is_featured": blog_post.is_featured,
            "published_date": blog_post.published_date.isoformat() if blog_post.published_date else None,
        }

        document = Document(page_content=embed_text, metadata=metadata)
        vector_id = f"blog_{blog_post.id}"
        self.vector_store.add_documents([document], ids=[vector_id])

        ChromaVector.objects.update_or_create(
            content_type="blog_post",
            content_id=blog_post.id,
            defaults={
                "vector_id": vector_id,
                "collection_name": "company_knowledge",
                "source_content_hash": self._get_content_hash(embed_text),
                "needs_update": False,
            },
        )

    def process_question(self, user_question: str, session_id: str = None) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì§ˆë¬¸ ì²˜ë¦¬ ë©”ì¸ í•¨ìˆ˜ - ë™ì  Few-shot ì ìš©"""
        start_time = datetime.now()

        print(f"ğŸ“ ì‚¬ìš©ì ì§ˆë¬¸: {user_question}")

        # ì§ˆë¬¸ ìœ í˜• ë¶„ì„
        question_type = self._analyze_question_type(user_question)
        print(f"ğŸ¯ ì§ˆë¬¸ ìœ í˜•: {question_type}")

        # ì§ˆë¬¸ ì „ì²˜ë¦¬
        processed_question = self._preprocess_question(user_question)
        print(f"ğŸ”„ ì „ì²˜ë¦¬ëœ ì§ˆë¬¸: {processed_question}")

        # ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
        relevant_docs = self._retrieve_relevant_documents(processed_question)
        print(f"ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(relevant_docs)}")

        # ê²€ìƒ‰ ê²°ê³¼ ë¶„ì„ ë° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_info = self._analyze_search_results(relevant_docs, user_question)
        print(f"ğŸ“Š ì»¨í…ìŠ¤íŠ¸ ì •ë³´: {context_info['summary']}")

        # ê´€ë ¨ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì°¾ê¸°
        related_blogs = self._find_related_blogs(context_info, user_question)
        print(f"ğŸ“ ê´€ë ¨ ë¸”ë¡œê·¸ ìˆ˜: {len(related_blogs)}")

        # ë™ì  Few-shot ì ìš©í•˜ì—¬ AI ë‹µë³€ ìƒì„±
        final_answer = self._generate_final_answer(user_question, context_info, related_blogs)

        # ê²°ê³¼ ë¡œê¹…
        response_time = (datetime.now() - start_time).total_seconds() * 1000
        chat_log = self._log_conversation(
            user_question, processed_question, context_info, related_blogs, final_answer, response_time, session_id
        )

        return {
            "answer": final_answer,
            "related_blogs": related_blogs,
            "sources_used": context_info["sources"],
            "response_time_ms": response_time,
            "chat_log_id": str(chat_log.id),
            "question_type": question_type,  # ë””ë²„ê¹…ìš©
        }

    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ (ê¸°ì¡´ê³¼ ë™ì¼)
    def _preprocess_question(self, question: str) -> str:
        processed = question.strip()
        keyword_mapping = {
            "í”„ë¡œì íŠ¸": ["í”„ë¡œì íŠ¸", "í¬íŠ¸í´ë¦¬ì˜¤", "ê°œë°œ", "ì‘ì—…", "ì—…ë¬´"],
            "ê¸°ìˆ ": ["ê¸°ìˆ ", "ìŠ¤íƒ", "ì–¸ì–´", "í”„ë ˆì„ì›Œí¬", "ë„êµ¬"],
            "íšŒì‚¬": ["íšŒì‚¬", "ê¸°ì—…", "ì¡°ì§", "íŒ€"],
        }
        for key, synonyms in keyword_mapping.items():
            if key in processed:
                processed += f" {' '.join(synonyms)}"
        return processed

    def _retrieve_relevant_documents(self, question: str, k: int = 10) -> List[Document]:
        retriever = MultiQueryRetriever.from_llm(
            retriever=self.vector_store.as_retriever(search_kwargs={"k": k}), llm=self.llm
        )
        try:
            documents = retriever.get_relevant_documents(question)
            return documents
        except Exception as e:
            print(f"âš ï¸ MultiQuery ê²€ìƒ‰ ì‹¤íŒ¨, ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´: {e}")
            return self.vector_store.similarity_search(question, k=k)

    def _analyze_search_results(self, documents: List[Document], question: str) -> Dict[str, Any]:
        company_contents = []
        projects = []
        blog_posts = []

        for doc in documents:
            source_type = doc.metadata.get("source_type")
            content_id = doc.metadata.get("content_id")

            if source_type == "company_content":
                try:
                    content = CompanyContent.objects.get(id=content_id)
                    company_contents.append(content)
                except CompanyContent.DoesNotExist:
                    continue
            elif source_type == "project":
                try:
                    project = Project.objects.get(id=content_id)
                    projects.append(project)
                except Project.DoesNotExist:
                    continue
            elif source_type == "blog_post":
                try:
                    blog = BlogPost.objects.get(id=content_id)
                    blog_posts.append(blog)
                except BlogPost.DoesNotExist:
                    continue

        if any(keyword in question.lower() for keyword in ["í”„ë¡œì íŠ¸", "í¬íŠ¸í´ë¦¬ì˜¤", "ê°œë°œ", "ì§„í–‰"]):
            highlight_projects = Project.objects.filter(is_portfolio_highlight=True).exclude(
                id__in=[p.id for p in projects]
            )[:3]
            projects.extend(highlight_projects)

        context_text = self._build_context_text(company_contents, projects, blog_posts)

        return {
            "company_contents": company_contents,
            "projects": projects,
            "blog_posts": blog_posts,
            "context_text": context_text,
            "sources": [doc.metadata for doc in documents],
            "summary": f"íšŒì‚¬ì •ë³´ {len(company_contents)}ê°œ, í”„ë¡œì íŠ¸ {len(projects)}ê°œ, ë¸”ë¡œê·¸ {len(blog_posts)}ê°œ ê²€ìƒ‰ë¨",
        }

    def _build_context_text(self, company_contents, projects, blog_posts) -> str:
        context_parts = []

        if company_contents:
            context_parts.append("## íšŒì‚¬ ì •ë³´")
            for content in company_contents[:3]:
                context_parts.append(f"**{content.title}**")
                context_parts.append(content.content[:500] + "...")
                context_parts.append("")

        if projects:
            context_parts.append("## í”„ë¡œì íŠ¸ í¬íŠ¸í´ë¦¬ì˜¤")
            for project in projects[:5]:
                context_parts.append(f"**{project.name}** ({project.get_project_type_display()})")
                context_parts.append(f"í´ë¼ì´ì–¸íŠ¸: {project.client_name}")
                context_parts.append(f"ì„¤ëª…: {project.description[:300]}...")
                context_parts.append(f"ê¸°ìˆ ìŠ¤íƒ: {', '.join(project.technologies_used)}")
                context_parts.append(f"ê¸°ê°„: {project.duration_months}ê°œì›”, íŒ€: {project.team_size}ëª…")
                if project.is_portfolio_highlight:
                    context_parts.append("ğŸŒŸ í¬íŠ¸í´ë¦¬ì˜¤ ëŒ€í‘œ í”„ë¡œì íŠ¸")
                context_parts.append("")

        if blog_posts:
            context_parts.append("## ê´€ë ¨ ë¸”ë¡œê·¸")
            for blog in blog_posts[:3]:
                context_parts.append(f"**{blog.title}**")
                context_parts.append(f"ìš”ì•½: {blog.content_summary[:200]}...")
                context_parts.append(f"URL: {blog.url}")
                context_parts.append("")

        return "\n".join(context_parts)

    def _find_related_blogs(self, context_info: Dict, question: str) -> List[Dict[str, str]]:
        related_blogs = []

        for blog_post in context_info["blog_posts"]:
            related_blogs.append(
                {
                    "title": blog_post.title,
                    "url": blog_post.url,
                    "excerpt": blog_post.excerpt[:100] + "..." if blog_post.excerpt else "",
                    "relevance": "ê²€ìƒ‰ ê²°ê³¼",
                }
            )

        for project in context_info["projects"]:
            project_blogs = BlogPost.objects.filter(related_projects=project, is_active=True).exclude(
                id__in=[b.id for b in context_info["blog_posts"]]
            )
            for blog in project_blogs[:2]:
                related_blogs.append(
                    {
                        "title": blog.title,
                        "url": blog.url,
                        "excerpt": blog.excerpt[:100] + "..." if blog.excerpt else "",
                        "relevance": f"{project.name} ê´€ë ¨",
                    }
                )

        return related_blogs[:5]

    def _log_conversation(
        self, user_question, processed_question, context_info, related_blogs, final_answer, response_time, session_id
    ) -> ChatLog:
        content_ids = [str(c.id) for c in context_info["company_contents"]]
        project_ids = [str(p.id) for p in context_info["projects"]]
        blog_ids = [str(b.id) for b in context_info["blog_posts"]]
        blog_links = [{"title": b["title"], "url": b["url"]} for b in related_blogs]

        chat_log = ChatLog.objects.create(
            user_question=user_question,
            processed_question=processed_question,
            retrieved_content_ids=content_ids,
            retrieved_projects=project_ids,
            retrieved_blogs=blog_ids,
            ai_response=final_answer,
            recommended_blog_links=blog_links,
            response_time_ms=int(response_time),
            session_id=session_id or "",
        )
        return chat_log

    def _get_content_hash(self, content: str) -> str:
        """ì»¨í…ì¸  í•´ì‹œ ìƒì„± (ë³€ê²½ ê°ì§€ìš©)"""
        return hashlib.sha256(content.encode()).hexdigest()

    def update_single_content(self, content_id: str, content_type: str):
        """íŠ¹ì • ì»¨í…ì¸  í•˜ë‚˜ë§Œ ì—…ë°ì´íŠ¸"""
        if content_type == "company_content":
            content = CompanyContent.objects.get(id=content_id)
            self._embed_company_content(content)
        elif content_type == "project":
            project = Project.objects.get(id=content_id)
            self._embed_project(project)
        elif content_type == "blog_post":
            blog = BlogPost.objects.get(id=content_id)
            self._embed_blog_post(blog)

    def add_custom_examples(self, question_type: str, examples: List[Dict]):
        """ë™ì ìœ¼ë¡œ ìƒˆë¡œìš´ ì˜ˆì‹œ ì¶”ê°€"""
        if question_type == "company":
            self.company_examples.extend(examples)
        elif question_type == "project":
            self.project_examples.extend(examples)
        elif question_type == "tech":
            self.tech_examples.extend(examples)
        elif question_type == "general":
            self.general_examples.extend(examples)

    def get_question_type_stats(self, days: int = 7) -> Dict[str, int]:
        """ìµœê·¼ Nì¼ê°„ ì§ˆë¬¸ ìœ í˜•ë³„ í†µê³„"""
        from datetime import timedelta

        from django.utils import timezone

        since_date = timezone.now() - timedelta(days=days)
        logs = ChatLog.objects.filter(created_at__gte=since_date)

        stats = {"company": 0, "project": 0, "tech": 0, "general": 0}

        for log in logs:
            question_type = self._analyze_question_type(log.user_question)
            stats[question_type] += 1

        return stats


# =================== ì‚¬ìš© ì˜ˆì‹œ ===================


def example_usage():
    """ë™ì  Few-shot ì±—ë´‡ ì‚¬ìš© ì˜ˆì‹œ"""

    # ì±—ë´‡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    chatbot = CompanyChatbotService()

    # ë‹¤ì–‘í•œ ìœ í˜•ì˜ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
    test_questions = [
        "ì´ íšŒì‚¬ëŠ” ë­í•˜ëŠ” íšŒì‚¬ì¸ê°€ìš”?",  # company íƒ€ì…
        "React ê°œë°œ ê°€ëŠ¥í•œê°€ìš”?",  # tech íƒ€ì…
        "ì–´ë–¤ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í–ˆë‚˜ìš”?",  # project íƒ€ì…
        "ê²¬ì  ë¬¸ì˜ëŠ” ì–´ë–»ê²Œ í•˜ë‚˜ìš”?",  # general íƒ€ì…
    ]

    for question in test_questions:
        print(f"\n{'=' * 50}")
        print(f"ì§ˆë¬¸: {question}")
        print(f"{'=' * 50}")

        result = chatbot.process_question(user_question=question, session_id="test_session_123")

        print(f"ì§ˆë¬¸ ìœ í˜•: {result['question_type']}")
        print(f"ë‹µë³€:\n{result['answer']}")
        print(f"ì‘ë‹µ ì‹œê°„: {result['response_time_ms']}ms")
        print(f"ê´€ë ¨ ë¸”ë¡œê·¸ ìˆ˜: {len(result['related_blogs'])}")

    return chatbot


def add_custom_examples_demo():
    """ì»¤ìŠ¤í…€ ì˜ˆì‹œ ì¶”ê°€ ë°ëª¨"""

    chatbot = CompanyChatbotService()

    # ìƒˆë¡œìš´ ê¸°ìˆ  ê´€ë ¨ ì˜ˆì‹œ ì¶”ê°€
    new_tech_examples = [
        {
            "question": "AI ê°œë°œ ê²½í—˜ì´ ìˆë‚˜ìš”?",
            "answer": """ë„¤! AI/ML ë¶„ì•¼ì—ì„œ ë‹¤ì–‘í•œ í”„ë¡œì íŠ¸ ê²½í—˜ì„ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ğŸ¤– **AI ê°œë°œ ì „ë¬¸ì„±**
- **ë¨¸ì‹ ëŸ¬ë‹**: scikit-learn, pandasë¥¼ í™œìš©í•œ ë°ì´í„° ë¶„ì„
- **ë”¥ëŸ¬ë‹**: TensorFlow, PyTorch ê¸°ë°˜ ëª¨ë¸ ê°œë°œ
- **ìì—°ì–´ì²˜ë¦¬**: LangChain, OpenAI API ì—°ë™ ê²½í—˜
- **ì»´í“¨í„°ë¹„ì „**: ì´ë¯¸ì§€ ë¶„ë¥˜, ê°ì²´ íƒì§€ í”„ë¡œì íŠ¸

ğŸ”¬ **ìµœê·¼ AI í”„ë¡œì íŠ¸**
- **ì±—ë´‡ ì‹œìŠ¤í…œ**: RAG ê¸°ë°˜ íšŒì‚¬ ì „ìš© ì±—ë´‡ ê°œë°œ
- **ì¶”ì²œ ì—”ì§„**: í˜‘ì—… í•„í„°ë§ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„
- **ê°ì • ë¶„ì„**: ê³ ê° ë¦¬ë·° ìë™ ë¶„ì„ ì‹œìŠ¤í…œ

ğŸ“ˆ **ì„±ê³¼**
- AI ëª¨ë¸ ì •í™•ë„ 90%+ ë‹¬ì„±
- ê¸°ì¡´ ëŒ€ë¹„ ì²˜ë¦¬ ì†ë„ 3ë°° í–¥ìƒ""",
        }
    ]

    # ì˜ˆì‹œ ì¶”ê°€
    chatbot.add_custom_examples("tech", new_tech_examples)

    # AI ê´€ë ¨ ì§ˆë¬¸ í…ŒìŠ¤íŠ¸
    result = chatbot.process_question("ë¨¸ì‹ ëŸ¬ë‹ ê°œë°œ ê°€ëŠ¥í•œê°€ìš”?")
    print(result["answer"])


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    chatbot = example_usage()

    # ì§ˆë¬¸ ìœ í˜•ë³„ í†µê³„ í™•ì¸
    stats = chatbot.get_question_type_stats(days=7)
    print(f"\nğŸ“Š ìµœê·¼ 7ì¼ ì§ˆë¬¸ ìœ í˜•ë³„ í†µê³„: {stats}")
